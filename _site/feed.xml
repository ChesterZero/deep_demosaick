<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.3">Jekyll</generator><link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:4000/" rel="alternate" type="text/html" /><updated>2018-09-06T12:41:45+03:00</updated><id>http://0.0.0.0:4000/</id><title type="html">Joint Image Demosaicking and Denoising with Iterative Networks</title><subtitle>Iterative Residual Network for Deep Joint Image Demosaicking and Denoising</subtitle><entry><title type="html">Results</title><link href="http://0.0.0.0:4000/results" rel="alternate" type="text/html" title="Results" /><published>2000-01-03T00:00:00+03:00</published><updated>2000-01-03T00:00:00+03:00</updated><id>http://0.0.0.0:4000/results</id><content type="html" xml:base="http://0.0.0.0:4000/results">&lt;center&gt;
&lt;iframe class=&quot;slideshow-iframe&quot; src=&quot;https://MarkusThill.github.io/slides/my-pics1.html&quot; width=&quot;800&quot; height=&quot;460&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; onload=&quot;resizeIframe(this)&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;

&lt;hr /&gt;
&lt;h1&gt;Find more high quality results at &lt;a href=&quot;https://photos.app.goo.gl/bizaGJZfezP5DkrC6&quot;&gt;Google Photos&lt;/a&gt;&lt;/h1&gt;

&lt;hr /&gt;
&lt;center&gt;
&lt;i class=&quot;fa fa-envelope fa-2x&quot;&gt;&lt;/i&gt;&lt;a href=&quot;mailto:filippos.kokkinos@skoltech.ru&quot;&gt;contact me&lt;/a&gt;
&lt;i class=&quot;fa fa-twitter fa-2x&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://twitter.com/filippos_kok&quot;&gt;@filippos_kok&lt;/a&gt;
&lt;i class=&quot;fa fa-linkedin fa-2x&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://www.linkedin.com/in/filippos-kokkinos-03343a138/&quot;&gt;Filippos Kokkinos&lt;/a&gt;
&lt;/center&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Downloads</title><link href="http://0.0.0.0:4000/downloads" rel="alternate" type="text/html" title="Downloads" /><published>2000-01-02T00:00:00+03:00</published><updated>2000-01-02T00:00:00+03:00</updated><id>http://0.0.0.0:4000/downloads</id><content type="html" xml:base="http://0.0.0.0:4000/downloads">&lt;h1&gt;Get the code &amp;amp; data&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Get &lt;strong&gt;code&lt;/strong&gt; from &lt;a href=&quot;https://github.com/cig-skoltech/deep_demosaick&quot;&gt;https://github.com/cig-skoltech/deep_demosaick&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Download &lt;strong&gt;data&lt;/strong&gt; from &lt;a href=&quot;https://drive.google.com/file/d/1DBc6Sul5vfnbP2dnx-51hqMTTVvEBAZO/view?usp=sharing&quot;&gt;https://drive.google.com/file/d/1DBc6Sul5vfnbP2dnx-51hqMTTVvEBAZO/view?usp=sharing&lt;/a&gt;. MIT dataset is not included, download seperately from &lt;a href=&quot;https://groups.csail.mit.edu/graphics/demosaicnet&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Use &lt;strong&gt;Application.ipynb&lt;/strong&gt; to demosaick real RAW images using one of the pre-trained models.&lt;/li&gt;
  &lt;li&gt;Training instructions can be found on &lt;strong&gt;ReadMe.md&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h1&gt;References&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Kokkinos, F., &amp;amp; Lefkimmiatis, S. (2018). Iterative Residual Network for Deep Joint Image Demosaicking and Denoising. arXiv preprint arXiv:1807.06403. &lt;a href=&quot;https://arxiv.org/abs/1807.06403&quot;&gt;(paper)&lt;/a&gt;&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Kokkinos, F., &amp;amp; Lefkimmiatis, S. (2018). Deep Image Demosaicking using a Cascade of Convolutional Residual Denoising Networks. arXiv preprint arXiv:1803.05215. &lt;a href=&quot;https://arxiv.org/abs/1803.05215&quot;&gt;(paper)&lt;/a&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h1&gt;Presentations&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Poster presented at ECCV 2018 Munich can be found &lt;a href=&quot;https://github.com/cig-skoltech/deep_demosaick/raw/gh-pages/files/ECCV2018_pdf.pdf&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Get the code &amp;amp; data Get code from https://github.com/cig-skoltech/deep_demosaick Download data from https://drive.google.com/file/d/1DBc6Sul5vfnbP2dnx-51hqMTTVvEBAZO/view?usp=sharing. MIT dataset is not included, download seperately from here. Use Application.ipynb to demosaick real RAW images using one of the pre-trained models. Training instructions can be found on ReadMe.md</summary></entry><entry><title type="html">Abstract</title><link href="http://0.0.0.0:4000/abstract" rel="alternate" type="text/html" title="Abstract" /><published>2000-01-01T00:00:00+03:00</published><updated>2000-01-01T00:00:00+03:00</updated><id>http://0.0.0.0:4000/abstract</id><content type="html" xml:base="http://0.0.0.0:4000/abstract">&lt;h1 class=&quot;text-green&quot;&gt;Iterative Residual Network for Deep Joint Image Demosaicking and Denoising&lt;/h1&gt;
&lt;h3&gt;&lt;a href=&quot;http://cig.skoltech.ru&quot;&gt;Filippos Kokkinos&lt;/a&gt;   &lt;a href=&quot;https://faculty.skoltech.ru/people/stamatioslefkimmiatis &quot;&gt;Stamatis Lefkimmiatis&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a href=&quot;http://cig.skoltech.ru&quot;&gt;SKOLTECH CIG&lt;/a&gt;&lt;/h4&gt;
&lt;h1 class=&quot;text-purple&quot;&gt;Abstract&lt;/h1&gt;
&lt;p style=&quot;font-size: 100%; text-align: center;&quot;&gt;Modern digital cameras rely on sequential execution of  separate  image  processing  steps  to  produce  realistic  images. The  first  two  steps  are  usually  related  to  denoising  and  demosaicking where the former aims to reduce noise from the sensor and the latter converts a series of light intensity readings to color images.  Modern  approaches  try  to  jointly  solve  these  problems, i.e joint denoising-demosaicking which is an inherently ill-posed problem  given  that  two-thirds  of  the  intensity  information  are missing and the rest are perturbed by noise. While there are several machine learning systems that have been recently introduced to solve this problem, in this work we propose a novel algorithm which  is  inspired  by  powerful  classical  image  regularization methods, large-scale  optimization and  deep  learning techniques. Consequently, our derived neural network has a transparent and clear  interpretation  compared  to  other  black-box  data  driven approaches.  Our  extensive  experimentation  line  demonstrates that our proposed network outperforms any previous approaches on both noisy and noise-free data across many different datasets. This  improvement  in  reconstruction  quality  is  attributed  to  the principled  way  we  design  our  network  architecture,  which  as  a result requires fewer trainable parameters than the current state-of-the art solution and furthermore can be efficiently trained by using a significantly smaller number of training data than existing deep  demosaicking  networks.&lt;/p&gt;

&lt;p&gt;&lt;span id=&quot;forkongithub&quot;&gt;
  &lt;a href=&quot;https://github.com/cig-skoltech/deep_demosaick&quot; class=&quot;bg-blue&quot;&gt;
    Fork me on GitHub
  &lt;/a&gt;
&lt;/span&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Iterative Residual Network for Deep Joint Image Demosaicking and Denoising Filippos Kokkinos   Stamatis Lefkimmiatis SKOLTECH CIG Abstract Modern digital cameras rely on sequential execution of separate image processing steps to produce realistic images. The first two steps are usually related to denoising and demosaicking where the former aims to reduce noise from the sensor and the latter converts a series of light intensity readings to color images. Modern approaches try to jointly solve these problems, i.e joint denoising-demosaicking which is an inherently ill-posed problem given that two-thirds of the intensity information are missing and the rest are perturbed by noise. While there are several machine learning systems that have been recently introduced to solve this problem, in this work we propose a novel algorithm which is inspired by powerful classical image regularization methods, large-scale optimization and deep learning techniques. Consequently, our derived neural network has a transparent and clear interpretation compared to other black-box data driven approaches. Our extensive experimentation line demonstrates that our proposed network outperforms any previous approaches on both noisy and noise-free data across many different datasets. This improvement in reconstruction quality is attributed to the principled way we design our network architecture, which as a result requires fewer trainable parameters than the current state-of-the art solution and furthermore can be efficiently trained by using a significantly smaller number of training data than existing deep demosaicking networks.</summary></entry></feed>